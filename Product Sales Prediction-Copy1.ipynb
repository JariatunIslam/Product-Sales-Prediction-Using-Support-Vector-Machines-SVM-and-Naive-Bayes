{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a847cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pdM\n",
    "df=pd.read_csv('Sales.csv') #dataset\n",
    "df.head()\n",
    "\n",
    "df.shape #rows and coloumns\n",
    "\n",
    "df.isnull().sum()\n",
    "\n",
    "Gender = pd.get_dummies(df, columns=['Gender'])\n",
    "\n",
    "Gender.head()\n",
    "\n",
    "X=df.iloc[:,[2,3]] #variable \n",
    "Y=df.iloc[:,[4]]   #target \n",
    "\n",
    "X.head()\n",
    "\n",
    "X.describe()\n",
    "\n",
    "Y.Purchased.value_counts(normalize=True)\n",
    "\n",
    "#split \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_Train,X_Test,Y_Train,Y_Test=train_test_split(X,Y,test_size=0.25,random_state=0)\n",
    "\n",
    "print(\"Training data: \",X_Train.shape)\n",
    "print(\"Test data: \",X_Test.shape)\n",
    "\n",
    "#feature\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler # to be units and precision\n",
    "sc_X=StandardScaler()\n",
    "X_Train=sc_X.fit_transform(X_Train) #transformation,mean and standard deviation from the training data during the fit step.\n",
    "X_Test=sc_X.transform(X_Test) \n",
    "\n",
    "#scatter plot train data , purple 0 yellow 1 \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(X_Train[:, 0], X_Train[:, 1],c=Y_Train.values.ravel()) \n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Estimated salary') \n",
    "plt.title('Train Data') \n",
    "plt.show()\n",
    "\n",
    "#scatter plot test data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(X_Test[:, 0], X_Test[:, 1],c=Y_Test.values.ravel()) \n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Estimated salary') \n",
    "plt.title('Test Data') \n",
    "plt.show()\n",
    "\n",
    "##model\n",
    "from sklearn.svm import SVC #algo\n",
    "#a kernel is a function that computes a similarity measure between pairs of data points in a given feature space.\n",
    "classifier=SVC(kernel='linear',random_state=0)  #hyperplane separates the different classes of data points\n",
    "classifier.fit(X_Train,Y_Train.values.ravel()) #train\n",
    "\n",
    "#predicting results\n",
    "Y_Pred=classifier.predict(X_Test) \n",
    "\n",
    "Y_Pred\n",
    "\n",
    "n=Y_Pred.shape[0]\n",
    "n\n",
    "\n",
    "from sklearn import metrics\n",
    "print('Accuracy(linear):',metrics.accuracy_score(Y_Test,Y_Pred))\n",
    "\n",
    "#hyperplane\n",
    "# plot datapoints  \n",
    "plt.scatter(X_Test[:, 0],X_Test[:, 1],c=Y_Test.values.ravel()) \n",
    "#plt.scatter (x Train:, 0), x Train:, 1), Train)\n",
    "\n",
    "\n",
    "# Create the hyperplane\n",
    "w = classifier.coef_[0]\n",
    "a = -w[0] / w[1]\n",
    "xx = np.linspace(-2.5, 2.5)\n",
    "yy = a * xx - (classifier.intercept_[0]) / w[1]\n",
    "\n",
    "# Plot the hyperplane\n",
    "plt.plot(xx, yy)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#confusion metrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(Y_Test,Y_Pred)\n",
    "\n",
    "print ('Confusion Matrix(GaussianNB)')\n",
    "cm\n",
    "\n",
    "TN = cm[0,0]\n",
    "print(\"True Negative:\",TN)\n",
    "\n",
    "FP=cm[0,1]\n",
    "print(\"False Possitive:\",FP)\n",
    "\n",
    "FN = cm[1,0]\n",
    "print(\"False Negative:\",FN)\n",
    "\n",
    "TP = cm[1,1]\n",
    "print(\"True Possitive:\",TP)\n",
    "\n",
    "#Again Accuracy\n",
    "(TN+TP)/n\n",
    "#TPR(True possitive rate) or Sensitivity\n",
    "recall = TP/(TP+FP)\n",
    "recall`\n",
    "\n",
    "#TNR/Specificity\n",
    "specificity = TN/(TN+FP)\n",
    "specificity\n",
    "\n",
    "#FPR\n",
    "FPR = 1-specificity\n",
    "FPR\n",
    "precision = TP/(TP+FP)\n",
    "precision\n",
    "\n",
    "#F1_score is the hermonic mean between precision and reall\n",
    "F1_score = (2*precision*recall)/(precision+recall)\n",
    "F1_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#or\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(Y_Test,Y_Pred)\n",
    "\n",
    "\n",
    "## ROC(Receiver operating characteristic) Curve \n",
    "#[plot between false positive rate and true positive rate]\n",
    "from sklearn.metrics import roc_curve\n",
    "probs = classifier.decision_function(X_Test)\n",
    "fpr, tpr, threshold = roc_curve(Y_Test, probs)\n",
    "\n",
    "# Reshape each array individually\n",
    "threshold_reshaped = threshold.reshape(-1, 1)\n",
    "fpr_reshaped = fpr.reshape(-1, 1)\n",
    "tpr_reshaped = tpr.reshape(-1, 1)\n",
    "\n",
    "# Horizontally stack the reshaped arrays\n",
    "stacked_data = np.hstack((threshold_reshaped, fpr_reshaped, tpr_reshaped))\n",
    "\n",
    "# Create a DataFrame with appropriate column names\n",
    "df = pd.DataFrame(stacked_data, columns=['threshold', 'fpr', 'tpr'])\n",
    "\n",
    "df.head()\n",
    "\n",
    "\n",
    "# from sklearn.metrics import roc_curve\n",
    "# probs = classifier.predict_proba(X_Test)\n",
    "# probs\n",
    "# prob_positive = probs[:, 1]\n",
    "# fpr, tpr, threshold = roc_curve(Y_Test, prob_positive)\n",
    "\n",
    "# # Reshape each array individually\n",
    "# threshold_reshaped = threshold.reshape(-1, 1)\n",
    "# fpr_reshaped = fpr.reshape(-1, 1)\n",
    "# tpr_reshaped = tpr.reshape(-1, 1)\n",
    "\n",
    "# # Horizontally stack the reshaped arrays\n",
    "# stacked_data = np.hstack((threshold_reshaped, fpr_reshaped, tpr_reshaped))\n",
    "\n",
    "# # Create a DataFrame with appropriate column names\n",
    "# df = pd.DataFrame(stacked_data, columns=['threshold', 'fpr', 'tpr'])\n",
    "\n",
    "# df.head()\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import auc\n",
    "roc_auc = auc(fpr,tpr)\n",
    "roc_auc\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title(\"receicer operating charecteristic\")\n",
    "plt.plot(fpr,tpr,'red',label = 'AUC-%0.2f'% roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "\n",
    "plt.plot([0,1],[0,1], color = 'darkblue',linestyle='--')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.show()\n",
    "\n",
    "#F1 flot\n",
    "\n",
    "thresholds = np.arange(0, 1.01, 0.01)  # Generate thresholds from 0 to 1\n",
    "f1_scores = [f1_score(Y_Test, Y_Pred > threshold) for threshold in thresholds]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(thresholds, f1_scores, label='F1 Score')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Score Curve')\n",
    "plt.legend(loc='lower left')\n",
    "plt.show()\n",
    "\n",
    "#Second\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "classifier_Rbf=SVC(kernel='rbf') #radial basis function\n",
    "classifier_Rbf.fit(X_Train,Y_Train.values.ravel())\n",
    "\n",
    "#predicting results\n",
    "Y_Pred=classifier_Rbf.predict(X_Test)\n",
    "\n",
    "print('Accuracy(rbf):',metrics.accuracy_score(Y_Test,Y_Pred))\n",
    "\n",
    "# Create a meshgrid for plotting the decision boundary\n",
    "h = 0.02\n",
    "x_min, x_max = X_Test[:, 0].min() - 1, X_Test[:, 0].max() + 1\n",
    "y_min, y_max = X_Test[:, 1].min() - 1, X_Test[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Predict class labels for the meshgrid points\n",
    "Z = classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot data points and decision boundary\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral, alpha=0.8)\n",
    "plt.scatter(X_Test[:, 0], X_Test[:, 1], c=Y_Test.values.ravel(), cmap=plt.cm.Spectral)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('SVM with RBF Kernel')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#confusion metrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(Y_Test,Y_Pred)\n",
    "\n",
    "print ('Confusion Matrix(GaussianNB)')\n",
    "cm\n",
    "\n",
    "TN = cm[0,0]\n",
    "print(\"True Negative:\",TN)\n",
    "\n",
    "FP=cm[0,1]\n",
    "print(\"False Possitive:\",FP)\n",
    "\n",
    "FN = cm[1,0]\n",
    "print(\"False Negative:\",FN)\n",
    "\n",
    "TP = cm[1,1]\n",
    "print(\"True Possitive:\",TP)\n",
    "\n",
    "#Again Accuracy\n",
    "(TN+TP)/n\n",
    "#TPR(True possitive rate) or Sensitivity\n",
    "recall = TP/(TP+FP)\n",
    "recall\n",
    "\n",
    "#TNR/Specificity\n",
    "specificity = TN/(TN+FP)\n",
    "specificity\n",
    "\n",
    "#FPR\n",
    "FPR = 1-specificity\n",
    "FPR\n",
    "precision = TP/(TP+FP)\n",
    "precision\n",
    "\n",
    "#F1_score is the hermonic mean between precision and reall\n",
    "F1_score = (2*precision*recall)/(precision+recall)\n",
    "F1_score\n",
    "\n",
    "\n",
    "#or\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(Y_Test,Y_Pred)\n",
    "\n",
    "## ROC(Receiver operating characteristic) Curve \n",
    "#[plot between false positive rate and true positive rate]\n",
    "from sklearn.metrics import roc_curve\n",
    "probs = classifier_Rbf.decision_function(X_Test)\n",
    "fpr, tpr, threshold = roc_curve(Y_Test, probs)\n",
    "\n",
    "# Reshape each array individually\n",
    "threshold_reshaped = threshold.reshape(-1, 1)\n",
    "fpr_reshaped = fpr.reshape(-1, 1)\n",
    "tpr_reshaped = tpr.reshape(-1, 1)\n",
    "\n",
    "# Horizontally stack the reshaped arrays\n",
    "stacked_data = np.hstack((threshold_reshaped, fpr_reshaped, tpr_reshaped))\n",
    "\n",
    "# Create a DataFrame with appropriate column names\n",
    "df = pd.DataFrame(stacked_data, columns=['threshold', 'fpr', 'tpr'])\n",
    "\n",
    "df.head()\n",
    "\n",
    "from sklearn.metrics import auc\n",
    "roc_auc = auc(fpr,tpr)\n",
    "roc_auc\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title(\"receicer operating charecteristic\")\n",
    "plt.plot(fpr,tpr,'red',label = 'AUC-%0.2f'% roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "\n",
    "plt.plot([0,1],[0,1], color = 'darkblue',linestyle='--')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.show()\n",
    "\n",
    "#F1 flot\n",
    "\n",
    "thresholds = np.arange(0, 1.01, 0.01)  # Generate thresholds from 0 to 1\n",
    "f1_scores = [f1_score(Y_Test, Y_Pred > threshold) for threshold in thresholds]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(thresholds, f1_scores, label='F1 Score')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Score Curve')\n",
    "plt.legend(loc='lower left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#third\n",
    "sv=SVC(kernel='poly',degree=4)\n",
    "sv.fit(X_Train,Y_Train.values.ravel())\n",
    "\n",
    "#predicting results\n",
    "Y_Pred=sv.predict(X_Test)\n",
    "\n",
    "print('Accuracy(poly):',metrics.accuracy_score(Y_Test,Y_Pred))\n",
    "\n",
    "# Create a meshgrid for plotting the decision boundary\n",
    "h = 0.02\n",
    "x_min, x_max = X_Test[:, 0].min() - 1, X_Test[:, 0].max() + 1\n",
    "y_min, y_max = X_Test[:, 1].min() - 1, X_Test[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Predict class labels for the meshgrid points\n",
    "Z = classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot data points and decision boundary\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral, alpha=0.8)\n",
    "plt.scatter(X_Test[:, 0], X_Test[:, 1], c=Y_Test.values.ravel(), cmap=plt.cm.Spectral)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('SVM with Polynomial Kernel (Degree 4)')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#confusion metrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(Y_Test,Y_Pred)\n",
    "\n",
    "print ('Confusion Matrix(GaussianNB)')\n",
    "cm\n",
    "\n",
    "TN = cm[0,0]\n",
    "print(\"True Negative:\",TN)\n",
    "\n",
    "FP=cm[0,1]\n",
    "print(\"False Possitive:\",FP)\n",
    "\n",
    "FN = cm[1,0]\n",
    "print(\"False Negative:\",FN)\n",
    "\n",
    "TP = cm[1,1]\n",
    "print(\"True Possitive:\",TP)\n",
    "\n",
    "#Again Accuracy\n",
    "(TN+TP)/n\n",
    "#TPR(True possitive rate) or Sensitivity\n",
    "recall = TP/(TP+FP)\n",
    "recall\n",
    "\n",
    "#TNR/Specificity\n",
    "specificity = TN/(TN+FP)\n",
    "specificity\n",
    "\n",
    "#FPR\n",
    "FPR = 1-specificity\n",
    "FPR\n",
    "precision = TP/(TP+FP)\n",
    "precision\n",
    "\n",
    "#F1_score is the hermonic mean between precision and reall\n",
    "F1_score = (2*precision*recall)/(precision+recall)\n",
    "F1_score\n",
    "\n",
    "#or\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(Y_Test,Y_Pred)\n",
    "\n",
    "## ROC(Receiver operating characteristic) Curve \n",
    "#[plot between false positive rate and true positive rate]\n",
    "from sklearn.metrics import roc_curve\n",
    "probs = sv.decision_function(X_Test)\n",
    "fpr, tpr, threshold = roc_curve(Y_Test, probs)\n",
    "\n",
    "# Reshape each array individually\n",
    "threshold_reshaped = threshold.reshape(-1, 1)\n",
    "fpr_reshaped = fpr.reshape(-1, 1)\n",
    "tpr_reshaped = tpr.reshape(-1, 1)\n",
    "\n",
    "# Horizontally stack the reshaped arrays\n",
    "stacked_data = np.hstack((threshold_reshaped, fpr_reshaped, tpr_reshaped))\n",
    "\n",
    "# Create a DataFrame with appropriate column names\n",
    "df = pd.DataFrame(stacked_data, columns=['threshold', 'fpr', 'tpr'])\n",
    "\n",
    "df.head()\n",
    "\n",
    "from sklearn.metrics import auc\n",
    "roc_auc = auc(fpr,tpr)\n",
    "roc_auc\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title(\"receicer operating charecteristic\")\n",
    "plt.plot(fpr,tpr,'red',label = 'AUC-%0.2f'% roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "\n",
    "plt.plot([0,1],[0,1], color = 'darkblue',linestyle='--')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.show()\n",
    "\n",
    "#F1 flot\n",
    "\n",
    "thresholds = np.arange(0, 1.01, 0.01)  # Generate thresholds from 0 to 1\n",
    "f1_scores = [f1_score(Y_Test, Y_Pred > threshold) for threshold in thresholds]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(thresholds, f1_scores, label='F1 Score')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Score Curve')\n",
    "plt.legend(loc='lower left')\n",
    "plt.show()\n",
    "\n",
    "#fourth\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_Train, Y_Train.values.ravel())\n",
    "\n",
    "Y_pred = nb.predict(X_Test)\n",
    "\n",
    "print('Accuracy(GaussianNB):', metrics.accuracy_score(Y_Test, Y_Pred))\n",
    "\n",
    "\n",
    "\n",
    "# Create a meshgrid for plotting the decision boundary\n",
    "h = 0.02\n",
    "x_min, x_max = X_Test[:, 0].min() - 1, X_Test[:, 0].max() + 1\n",
    "y_min, y_max = X_Test[:, 1].min() - 1, X_Test[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Predict class labels for the meshgrid points\n",
    "Z = classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot data points and decision boundary\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral, alpha=0.8)\n",
    "plt.scatter(X_Test[:, 0], X_Test[:, 1], c=Y_Test.values.ravel(), cmap=plt.cm.Spectral)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('Gaussian')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#seond part \n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(Y_Test,Y_Pred)\n",
    "\n",
    "print ('Confusion Matrix(GaussianNB)')\n",
    "cm\n",
    "\n",
    "TN = cm[0,0]\n",
    "print(\"True Negative:\",TN)\n",
    "\n",
    "FP=cm[0,1]\n",
    "print(\"False Possitive:\",FP)\n",
    "\n",
    "FN = cm[1,0]\n",
    "print(\"False Negative:\",FN)\n",
    "\n",
    "TP = cm[1,1]\n",
    "print(\"True Possitive:\",TP)\n",
    "\n",
    "#Again Accuracy\n",
    "(TN+TP)/n\n",
    "#TPR(True possitive rate) or Sensitivity\n",
    "recall = TP/(TP+FP)\n",
    "recall\n",
    "\n",
    "#TNR/Specificity\n",
    "specificity = TN/(TN+FP)\n",
    "specificity\n",
    "\n",
    "#FPR\n",
    "FPR = 1-specificity\n",
    "FPR\n",
    "precision = TP/(TP+FP)\n",
    "precision\n",
    "\n",
    "#F1_score is the hermonic mean between precision and reall\n",
    "F1_score = (2*precision*recall)/(precision+recall)\n",
    "F1_score\n",
    "\n",
    "#or\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(Y_Test,Y_Pred)\n",
    "\n",
    "## ROC(Receiver operating characteristic) Curve \n",
    "#[plot between false positive rate and true positive rate]\n",
    "from sklearn.metrics import roc_curve\n",
    "probs = nb.predict_proba(X_Test)\n",
    "probs\n",
    "prob_positive = probs[:, 1]\n",
    "fpr, tpr, threshold = roc_curve(Y_Test, prob_positive)\n",
    "\n",
    "\n",
    "\n",
    "# Reshape each array individually\n",
    "threshold_reshaped = threshold.reshape(-1, 1)\n",
    "fpr_reshaped = fpr.reshape(-1, 1)\n",
    "tpr_reshaped = tpr.reshape(-1, 1)\n",
    "\n",
    "\n",
    "# Horizontally stack the reshaped arrays\n",
    "stacked_data = np.hstack((threshold_reshaped, fpr_reshaped, tpr_reshaped))\n",
    "\n",
    "# Create a DataFrame with appropriate column names\n",
    "df = pd.DataFrame(stacked_data, columns=['threshold', 'fpr', 'tpr'])\n",
    "\n",
    "df.head()\n",
    "\n",
    "\n",
    "from sklearn.metrics import auc\n",
    "roc_auc = auc(fpr,tpr)\n",
    "roc_auc\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title(\"receicer operating charecteristic\")\n",
    "plt.plot(fpr,tpr,'red',label = 'AUC-%0.2f'% roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "\n",
    "plt.plot([0,1],[0,1], color = 'darkblue',linestyle='--')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.show()\n",
    "\n",
    "#F1 flot\n",
    "\n",
    "thresholds = np.arange(0, 1.01, 0.01)  # Generate thresholds from 0 to 1\n",
    "f1_scores = [f1_score(Y_Test, Y_Pred > threshold) for threshold in thresholds]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(thresholds, f1_scores, label='F1 Score')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Score Curve')\n",
    "plt.legend(loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ab15b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2e9cde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dedc598",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
